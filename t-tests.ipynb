{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Sample T-Test\n",
    "A one-sample t-test checks whether a sample mean differs from the population mean. Let's create some dummy data for the population and a sample and test whether the average value of the sample differs from the average value of the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(8)\n",
    "population = stats.poisson.rvs(loc=0, mu=50, size=100000)\n",
    "sample = stats.poisson.rvs(loc=0, mu=48, size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used a slightly different distribution to generate the sample data, so we know that the two means are different. Let's conduct a t-test at a 95% confidence level and see if it correctly rejects the null hypothesis that the sample comes from the same distribution as the population. To conduct a one sample t-test, we use the stats.ttest_1samp() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -2.59\n",
      "p-value: 0.01\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_val = stats.ttest_1samp(a=sample, popmean=population.mean())\n",
    "\n",
    "print('t-statistic: {0}'.format(round(t_stat, 2)))\n",
    "print('p-value: {0}'.format(round(p_val, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test result shows the test statistic is equal to -2.59. This test statistic tells us how much the sample mean deviates from the null hypothesis. If the t-statistic lies outside the quantiles of the t-distribution corresponding to our confidence level and degrees of freedom, we reject the null hypothesis. We can check the quantiles with stats.t.ppf()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-critical value: 1.98\n"
     ]
    }
   ],
   "source": [
    "t_critical = stats.t.ppf(q=0.975, df=99)\n",
    "\n",
    "print('t-critical value: {0}'.format(round(t_critical, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can calculate the chances of seeing a result as extreme as the one we observed (known as the p-value) by passing the t-statistic in as the quantile to the stats.t.cdf() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.01\n"
     ]
    }
   ],
   "source": [
    "print('p-value: {0}'.format(round(stats.t.cdf(x=t_stat, df=99)*2, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The alternative hypothesis we are checking is whether the sample mean differs (is not equal to) the population mean. Since the sample could differ in either the positive or negative direction we multiply by two.\n",
    "Notice this value is the same as the p-value listed in the original t-test output. A p-value of 0.01 means we'd expect to see data as extreme as our sample due to chance about 1% of the time if the null hypothesis was true. In this case, the p-value is lower than our significance level Î± (equal to 1 - confidence level or 0.05) so we should reject the null hypothesis. If we were to construct a 95% confidence interval for the sample it would not capture population mean of 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI: 46.39, 49.49\n"
     ]
    }
   ],
   "source": [
    "sigma = sample.std()/math.sqrt(100)\n",
    "left_val, right_val = stats.t.interval(0.95, df=99, loc=sample.mean(), scale=sigma)\n",
    "\n",
    "print('CI: {0}, {1}'.format(round(left_val, 2), round(right_val, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the other hand, since there is a 1.3% chance of seeing a result this extreme due to chance, it is not significant at the 99% confidence level. This means if we were to construct a 99% confidence interval, it would capture the population mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CI: 45.89, 49.99\n"
     ]
    }
   ],
   "source": [
    "sigma = sample.std()/math.sqrt(100)\n",
    "left_val, right_val = stats.t.interval(0.99, df=99, loc=sample.mean(), scale=sigma)\n",
    "\n",
    "print('CI: {0}, {1}'.format(round(left_val, 2), round(right_val, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a higher confidence level, we construct a wider confidence interval and increase the chances that it captures to true mean, thus making it less likely that we'll reject the null hypothesis. In this case, the p-value of 0.0109 is greater than our significance level of 0.01 and we fail to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Two-Sample T-Test\n",
    "A two-sample t-test investigates whether the means of two independent data samples differ from one another. In a two-sample test, the null hypothesis is that the means of both groups are the same. Unlike the one sample-test where we test against a known population parameter, the two sample test only involves sample means. You can conduct a two-sample t-test by passing with the stats.ttest_ind() function. Let's generate two data samples and test it against each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(8)\n",
    "first_sample = stats.poisson.rvs(loc=0, mu=30, size=20)\n",
    "second_sample = stats.poisson.rvs(loc=0, mu=25, size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: 2.4\n",
      "p-value: 0.02\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_val = stats.ttest_ind(a=first_sample, b=second_sample, equal_var=False)\n",
    "\n",
    "print('t-statistic: {0}'.format(round(t_stat, 2)))\n",
    "print('p-value: {0}'.format(round(p_val, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test yields a p-value of 0.02, which means there is a 2% chance we'd see sample data this far apart if the two groups tested are actually identical. If we were using a 99% confidence level we would fail to reject the null hypothesis, since the p-value is greater than the corresponding significance level of 1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paired T-Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic two sample t-test is designed for testing differences between independent groups. In some cases, you might be interested in testing differences between samples of the same group at different points in time. For instance, a hospital might want to test whether a drug works by checking the parameters of the same group of patients before and after treatment. A paired t-test lets you check whether the means of samples from the same group differ.\n",
    "We can conduct a paired t-test using the scipy function stats.ttest_rel(). Let's generate some data and do a paired t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean difference: 8.58\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(8)\n",
    "before_treatment = stats.norm.rvs(scale=10, loc=200, size=100)\n",
    "after_treatment = before_treatment + stats.norm.rvs(scale=40, loc=10, size=100)\n",
    "difference = after_treatment - before_treatment\n",
    "\n",
    "df = pd.DataFrame({'Before treatment': before_treatment, \n",
    "                   'After treatment': after_treatment, \n",
    "                   'Difference': difference})\n",
    "\n",
    "print('Mean difference: {0}'.format(round(df.Difference.mean(), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The summary shows that the mean difference is about 8 on average after treatment. Let's conduct a paired t-test to see whether this difference is significant at a 95% confidence level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -1.95\n",
      "p-value: 0.05\n"
     ]
    }
   ],
   "source": [
    "t_stat, p_val = stats.ttest_rel(a=before_treatment, b=after_treatment)\n",
    "print('t-statistic: {0}'.format(round(t_stat, 2)))\n",
    "print('p-value: {0}'.format(round(p_val, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The p-value in the test output shows that the chances of seeing this large of a difference between samples due to chance is 5%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
